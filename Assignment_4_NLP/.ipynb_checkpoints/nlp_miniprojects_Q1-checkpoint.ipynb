{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource u'corpora/stopwords' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Havoc\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\WinPython-64bit-2.7.10.2\\\\settings/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Havoc\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\WinPython-64bit-2.7.10.2\\\\python-2.7.10.amd64\\\\nltk_data'\n    - 'C:\\\\Users\\\\Havoc\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\WinPython-64bit-2.7.10.2\\\\python-2.7.10.amd64\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Havoc\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ecc8d936648f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;34m'''Initializing stopwords and adding new stopwords to the list'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[0mstop_words_additions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'll'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'adwmuxsza'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'abc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aac'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aardbark'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aabc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aab'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aaa'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aa'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'that'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'youre'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zzcrkebcrfxbb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'i\\'m'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'he\\'s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'i\\'ve'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'it\\'s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'im'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'its'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Havoc\\AppData\\Local\\Programs\\Python\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\nltk\\corpus\\util.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Havoc\\AppData\\Local\\Programs\\Python\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\nltk\\corpus\\util.pyc\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'corpora/%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource u'corpora/stopwords' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Havoc\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\WinPython-64bit-2.7.10.2\\\\settings/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Havoc\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\WinPython-64bit-2.7.10.2\\\\python-2.7.10.amd64\\\\nltk_data'\n    - 'C:\\\\Users\\\\Havoc\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\WinPython-64bit-2.7.10.2\\\\python-2.7.10.amd64\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Havoc\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "'''Importing modules'''\n",
    "import pandas\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import json\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin, TransformerMixin\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso, SGDRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import dill\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sys import getsizeof\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "import gzip\n",
    "\n",
    "'''Initializing variables and empty lists'''\n",
    "dict_list = []\n",
    "iter_lines = 0\n",
    "iter_lower_split = 0\n",
    "text_list_lower_split = []\n",
    "a = 0\n",
    "\n",
    "'''Initializing class containing a machine learning model (Ridge Regression)\n",
    "class mlm_RidR(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self):\n",
    "        self.rr = Ridge()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.rr.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def best_params_(self):\n",
    "        return self.rr.best_params_\n",
    "    \n",
    "    def predict(self, X):        \n",
    "        return self.rr.predict(X)'''\n",
    "\n",
    "'''Opening txt file containing Yelp review data and reading all lines'''\n",
    "yelp_dataset_txt = gzip.open('yelp_train_academic_dataset_review.json.gz', 'rb+')\n",
    "raw_lines = yelp_dataset_txt.readlines()\n",
    "\n",
    "'''Writing raw_lines to an empty list using json.loads to parse'''\n",
    "while iter_lines < 1000: #len(raw_lines):\n",
    "    if len(raw_lines[iter_lines]) > 0:\n",
    "        dict_list.append(json.loads(raw_lines[iter_lines]))\n",
    "    iter_lines += 1\n",
    "    \n",
    "'''Initializing list with Yelp data into a pandas data frame for manipulation'''\n",
    "data_frame = pandas.DataFrame(dict_list).to_dict()\n",
    "\n",
    "'''Closing txt files'''\n",
    "yelp_dataset_txt.close()\n",
    "\n",
    "'''Initializing stars and text lists'''\n",
    "stars_list = data_frame['stars'].values()\n",
    "text_list = data_frame['text'].values()\n",
    "\n",
    "'''Initializing stopwords and adding new stopwords to the list'''\n",
    "stop_words = [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', 'll', 'adwmuxsza', 'zu', 'abc', 'aac', 'aardbark', 'aabc', 'aab', 'aaa', 'aa', 'that', 'youre', 'zzcrkebcrfxbb', 'zse', 'i\\'m', 'he\\'s', 'i\\'ve', 'it\\'s', 'id', 'im', 'hes', 'ive', 'its']\n",
    "    \n",
    "'''Looping through text_list converting to lower case and splitting into individual terms'''\n",
    "while iter_lower_split < len(text_list):\n",
    "    text_list_lower = text_list[iter_lower_split].lower()\n",
    "    text_list_split = text_list_lower.split()\n",
    "    text_list_split = [w for w in text_list_split if not w in stop_words]\n",
    "    text_list_split = (' '.join(text_list_split))\n",
    "    text_list_split = re.findall('[a-z]{2,}', text_list_split)\n",
    "    text_list_split = (' '.join(text_list_split))\n",
    "    text_list_lower_split.append(text_list_split)\n",
    "    iter_lower_split += 1\n",
    "    \n",
    "'''Initializing analytical model axes'''\n",
    "X = text_list_lower_split\n",
    "y = stars_list\n",
    "\n",
    "'''Splitting axes variables into train and test sets'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
    "    \n",
    "'''Creating and Initializing Pipeline'''\n",
    "pipe_line = Pipeline([('count_vectorizer', CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, min_df = 0.001, max_df = 0.4)), \n",
    "                      ('ridge_regression', Ridge(alpha = 150))])\n",
    "\n",
    "'''GridSearchCV to find best parameters'''\n",
    "'''grid_search = GridSearchCV(pipe_line, {'ridge_regression__alpha': range(0, 1000, 10)})\n",
    "grid_search.fit(X_train, y_train)\n",
    "print grid_search.best_params_\n",
    "print grid_search.score(X_train, y_train)\n",
    "print grid_search.score(X_test, y_test)'''\n",
    "\n",
    "'''Calling Pipeline to fit and score datasets'''\n",
    "pipe_line.fit(X_train, y_train)\n",
    "print pipe_line.score(X_train, y_train)\n",
    "print pipe_line.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
